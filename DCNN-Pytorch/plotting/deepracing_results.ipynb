{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=11, micro=8, releaselevel='final', serial=0)\n",
      "/home/trent/deepracingws/src/deepracing\n",
      "/home/trent/deepracingws/MTR\n",
      "['/home/trent/deepracingws/MTR', '/home/trent/deepracingws/src/deepracing/DCNN-Pytorch', '/home/trent/deepracingws/src/deepracing/deepracing_py', '/home/trent/deepracingws/src/deepracing/DCNN-Pytorch/plotting', '', '/home/trent/iacws/install/lib/python3.11/site-packages', '/home/trent/source_builds/ros2iron/install/lib/python3.11/dist-packages', '/home/trent/source_builds/ros2iron/install/lib/python3.11/site-packages', '/home/trent/python3venvs/python311_deepracing/lib/python3.11/site-packages', '/opt/module/python311/lib/python311.zip', '/opt/module/python311/lib/python3.11', '/opt/module/python311/lib/python3.11/lib-dynload']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure, matplotlib.axes\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import yaml \n",
    "import tqdm\n",
    "import collections.abc\n",
    "import torch\n",
    "from utils import PredictionResults\n",
    "import os\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "deepracing_path = os.environ[\"DEEPRACING_PATH\"]\n",
    "print(deepracing_path)\n",
    "\n",
    "deepracingmodelsdir = os.path.abspath(os.path.join(deepracing_path, \"DCNN-Pytorch\"))\n",
    "deepracingdir = os.path.abspath(os.path.join(deepracing_path, \"deepracing_py\"))\n",
    "if (not (deepracingmodelsdir in sys.path)) or (not (deepracingdir in sys.path)):\n",
    "    sys.path = [deepracingmodelsdir, deepracingdir] + sys.path\n",
    "\n",
    "homedir = os.environ[\"HOME\"]\n",
    "\n",
    "mtrdir=os.path.join(homedir, \"deepracingws\", \"MTR\")\n",
    "print(mtrdir)\n",
    "if (not (mtrdir in sys.path)):\n",
    "    sys.path.insert(0, mtrdir)\n",
    "print(sys.path)\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_0/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_1/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_2/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_3/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_4/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_5/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_6/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_7/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_8/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_9/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_10/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_11/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_12/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_13/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_14/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_15/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_16/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_17/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_18/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Bahrain_7_13_2023_15_43_22_trajectory_data/car_19/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_1/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_2/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_3/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_6/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_7/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_8/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_10/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_12/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_16/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_17/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Britain_7_6_2023_16_10_29_trajectory_data/car_18/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_0/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_1/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_2/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_3/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_4/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_5/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_6/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_7/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_8/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_9/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_10/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_11/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_12/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_13/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_14/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_15/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_16/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_17/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_18/metadata.yaml\n",
      "Loading data for /p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard/Jeddah_7_13_2023_15_27_32_trajectory_data/car_19/metadata.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from deepracing_models.data_loading import SubsetFlag\n",
    "import deepracing_models.math_utils as mu\n",
    "import deepracing_models.data_loading.file_datasets as FD\n",
    "import deepracing_models.data_loading.utils.file_utils as file_utils\n",
    "import torch.utils.data as torchdata\n",
    "keys : set = {\n",
    "    \"hist\",\n",
    "    \"hist_quats\",\n",
    "    \"hist_vel\",\n",
    "    \"fut\",\n",
    "    \"fut_quats\",\n",
    "    \"fut_vel\",\n",
    "    \"left_bd\",\n",
    "    \"right_bd\",\n",
    "    \"future_left_bd\",\n",
    "    \"future_right_bd\",\n",
    "    \"thistory\",\n",
    "    \"tfuture\"\n",
    "}\n",
    "dsets : list[FD.TrajectoryPredictionDataset] = \\\n",
    "    file_utils.load_datasets_from_files(\"/p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard\",\n",
    "                                     flag=SubsetFlag.TEST, keys=keys)\n",
    "fulldset : torchdata.ConcatDataset = torchdata.ConcatDataset(dsets)\n",
    "\n",
    "\n",
    "bezier_experiment = \"widespread_beans_6059\"\n",
    "bezier_results_dir = os.path.join(\"/p/DeepRacing/mixnet_bezier_results\", bezier_experiment)\n",
    "bezier_results = PredictionResults.from_data_file(os.path.join(bezier_results_dir, \"data.npz\"), \"BezierMixNet\")\n",
    "bezier_results.compute_fde()\n",
    "\n",
    "# composite_experiment = \"sunny_coyote_3579\"\n",
    "composite_experiment = \"chosen_preservative_7505\"\n",
    "composite_results_dir = os.path.join(\"/p/DeepRacing/bamf_results\", composite_experiment)\n",
    "composite_results = PredictionResults.from_data_file(os.path.join(composite_results_dir, \"data.npz\"), \"BARTÃ©\")\n",
    "composite_results.compute_fde()\n",
    "composite_curves = torch.as_tensor(composite_results[\"curves\"], dtype=torch.float64, device=torch.device(\"cpu\"))\n",
    "kbezier = composite_curves.shape[-2] - 1\n",
    "num_segments = composite_curves.shape[-3]\n",
    "tfuture_np = np.stack([fulldset[i][\"tfuture\"] for i in range(len(fulldset))], axis=0)\n",
    "tfuture = torch.as_tensor(tfuture_np, dtype=composite_curves.dtype, device=composite_curves.device)\n",
    "tfuture = tfuture - tfuture[:,[0,]]\n",
    "tswitch = torch.stack([torch.linspace(tfuture[i,0], tfuture[i,-1], steps=num_segments+1, dtype=tfuture.dtype, device=tfuture.device) for i in range(tfuture.shape[0])], dim=0)\n",
    "tstart = tswitch[:,:-1]\n",
    "tend = tswitch[:,1:]\n",
    "dt = tend - tstart\n",
    "composite_curve_derivs = kbezier*(composite_curves[:,:,1:] - composite_curves[:,:,:-1])/(dt[:,:,None,None])\n",
    "vels_eval, _ = mu.compositeBezierEval(tstart, dt, composite_curve_derivs, tfuture)\n",
    "composite_results[\"vel_predictions\"] = vels_eval.cpu().numpy()\n",
    "\n",
    "\n",
    "mixnet_experiment = \"agricultural_flue_8932\"\n",
    "mixnet_results_dir = os.path.join(\"/p/DeepRacing/mixnet_results\", mixnet_experiment)\n",
    "mixnet_results = PredictionResults.from_data_file(os.path.join(mixnet_results_dir, \"data.npz\"), \"MixNet\")\n",
    "mixnet_results[\"ground_truth\"] = np.stack([fulldset[i][\"fut\"].copy() for i in range(len(fulldset))], axis=0)\n",
    "mixnet_results.compute_fde()\n",
    "\n",
    "mtr_experiment = \"formal_pedestal_9890\"\n",
    "mtr_results_dir =  os.path.join(\"/p/DeepRacing/mtr_results\", mtr_experiment)\n",
    "mtr_data_dir = \"/p/DeepRacing/unpacked_datasets/local_fitting/v1/mtr_format/1second\"\n",
    "mtr_scenarios_dir = os.path.join(mtr_data_dir, \"processed_scenarios_test\")\n",
    "mtr_sortfile = os.path.join(mtr_results_dir, \"test_plots\", \"idx_sort.npz\")\n",
    "if not os.path.isfile(mtr_sortfile):\n",
    "    with open(os.path.join(mtr_data_dir, \"processed_scenarios_test_infos.pkl\"), \"rb\") as f:\n",
    "        mtr_infos = pkl.load(f)\n",
    "    mtr_keys = mtr_infos[0].keys()\n",
    "    entries = []\n",
    "    for (idx, info) in tqdm.tqdm(enumerate(mtr_infos), total=len(mtr_infos)):\n",
    "        scenario_id = info[\"scenario_id\"]\n",
    "        with open(os.path.join(mtr_scenarios_dir, scenario_id+\".metadata.yaml\"), \"r\") as f:\n",
    "            scenario_metadata = yaml.safe_load(f)\n",
    "        deepracing_dir = os.path.dirname(scenario_metadata[\"deepracing_file\"])\n",
    "        dset_index = scenario_metadata[\"index\"]\n",
    "        car_index = int(os.path.basename(deepracing_dir).split(\"_\")[-1])\n",
    "        dated_trackname : str = os.path.basename(os.path.dirname(deepracing_dir))\n",
    "        trackname = dated_trackname.split(\"_\")[0]\n",
    "        entries.append((idx, scenario_id, trackname, car_index, dset_index))\n",
    "    entries_sorted = sorted(entries, key=lambda entry : (entry[2], entry[3], entry[4]))\n",
    "    scenario_ids_sorted = np.asarray([e[1] for e in entries_sorted], dtype=object)\n",
    "    idx_sort = np.asarray([e[0] for e in entries_sorted], dtype=np.int64)\n",
    "    with open(mtr_sortfile, \"wb\") as f:\n",
    "        np.savez(f, idx_sort=idx_sort, scenario_ids=scenario_ids_sorted)\n",
    "\n",
    "with open(mtr_sortfile, \"rb\") as f:\n",
    "    npfile = np.load(f, allow_pickle=True)\n",
    "    sort_idx_mtr = npfile[\"idx_sort\"].copy()\n",
    "    scenario_ids_sorted = npfile[\"scenario_ids\"].copy()\n",
    "\n",
    "mtr_results = PredictionResults.from_data_file(os.path.join(mtr_results_dir, \"test_plots\", \"data.npz\"), \"MTR\", sort_idx=sort_idx_mtr)\n",
    "mtr_results[\"predictions_all\"] = mtr_results[\"predictions\"].copy()\n",
    "mtr_results[\"predictions\"] = np.zeros_like(mtr_results[\"predictions_all\"][:,0])\n",
    "for idx in range(mtr_results[\"predictions_all\"].shape[0]):\n",
    "    mtr_results[\"predictions\"][idx] = mtr_results[\"predictions_all\"][idx,mtr_results[\"best_curve_idx\"][idx]]\n",
    "mtr_results.compute_fde()\n",
    "# for k in [\"history\", \"ground_truth\"]\n",
    "\n",
    "all_history = np.stack([fulldset[i][\"hist\"] for i in range(len(fulldset))], axis=0)\n",
    "all_leftbound = np.stack([fulldset[i][\"future_left_bd\"] for i in range(len(fulldset))], axis=0)\n",
    "all_rightbound = np.stack([fulldset[i][\"future_right_bd\"] for i in range(len(fulldset))], axis=0)\n",
    "for result in [bezier_results, mtr_results, composite_results, mixnet_results]:\n",
    "    result[\"left_bd\"] = all_leftbound.copy()\n",
    "    result[\"right_bd\"] = all_rightbound.copy()\n",
    "    print(\"%s has %d points\" % (result.modelname, result[\"history\"].shape[0]))\n",
    "    print(\"%s has keys: %s\" % (result.modelname, str(list(result.keys()))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from torch.utils.data import Subset\n",
    "from utils import plot_error_histograms, plot_outliers\n",
    "\n",
    "whis=None\n",
    "pf=98.0\n",
    "metric=\"ade\"\n",
    "results_base = \"/p/DeepRacing/trajectory_prediction_results/sim_data\"\n",
    "nonoutliers, _ = composite_results.trim_percentiles(metric=metric, pf=pf)\n",
    "outliers = ~nonoutliers\n",
    "print(len(fulldset))\n",
    "print(np.sum(nonoutliers))\n",
    "print(np.sum(outliers))\n",
    "\n",
    "composite_results_trimmed = composite_results.subsample(nonoutliers)\n",
    "bezier_results_trimmed = bezier_results.subsample(nonoutliers)\n",
    "mtr_results_trimmed = mtr_results.subsample(nonoutliers)\n",
    "mixnet_results_trimmed = mixnet_results.subsample(nonoutliers)\n",
    "fulldset_trimmed = Subset(fulldset, [i for i in range(nonoutliers.shape[0]) if bool(nonoutliers[i])])\n",
    "\n",
    "\n",
    "# print(np.sum(mtr_nonoutliers*(~barte_nonoutliers)))\n",
    "# print(np.sum(barte_nonoutliers*(~mtr_nonoutliers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "rcparams_latex = {\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "}\n",
    "\n",
    "plots_dir = os.path.join(results_base, \"plots\")\n",
    "histograms_dir = os.path.join(results_base, \"histograms\")\n",
    "plots_dir_trimmed = os.path.join(results_base, \"plots_trimmed\")\n",
    "histograms_dir_trimmed = os.path.join(results_base, \"histograms_trimmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_table\n",
    "from texttable import Texttable\n",
    "\n",
    "results_textable = create_table([composite_results, mtr_results, mixnet_results, bezier_results])\n",
    "results_textable.set_deco(Texttable.BORDER | Texttable.HLINES | Texttable.HEADER | Texttable.VLINES)\n",
    "print(results_textable.draw())\n",
    "results_trimmed_textable = create_table([composite_results_trimmed, mtr_results_trimmed, mixnet_results_trimmed, bezier_results_trimmed])\n",
    "results_trimmed_textable.set_deco(Texttable.BORDER | Texttable.HLINES | Texttable.HEADER | Texttable.VLINES)\n",
    "print(results_trimmed_textable.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maindir = \"/p/DeepRacing/trajectory_prediction_results/sim_data/cross_error_analysis\"\n",
    "basedir = os.path.join(maindir, metric)\n",
    "all_results_composite_ref = [composite_results, mtr_results, mixnet_results, bezier_results]\n",
    "all_results_mtr_ref = [mtr_results, composite_results, mixnet_results, bezier_results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "cross_error_analysis(all_results_composite_ref, fulldset, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis(all_results_mtr_ref, fulldset, basedir, pf=None, whis=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "cross_error_analysis(all_results_composite_ref, fulldset, basedir, other_models=[mtr_results.modelname,], pf=pf, whis=whis, metric=metric)\n",
    "cross_error_analysis(all_results_mtr_ref, fulldset, basedir, other_models=[composite_results.modelname,], pf=pf, whis=whis, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_samples = composite_results[metric].shape[0]\n",
    "\n",
    "barte_nonoutliers, barte_maxval = composite_results.trim_percentiles(metric=metric, pf=pf)\n",
    "mtr_nonoutliers, mtr_maxval = mtr_results.trim_percentiles(metric=metric, pf=pf)\n",
    "\n",
    "# mtr_nonoutliers, mtr_maxval = mtr_results.trim_iqr(metric=metric, whis=whis)\n",
    "# barte_nonoutliers, barte_maxval = composite_results.trim_iqr(metric=metric, whis=whis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barte_inliers = composite_results[metric]<=barte_maxval \n",
    "mtr_inliers = mtr_results[metric]<=mtr_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_merged\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barte_inliers = composite_results[metric]<=barte_maxval \n",
    "mtr_inliers = mtr_results[metric]<=barte_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_barte_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barte_inliers = composite_results[metric]<=mtr_maxval\n",
    "mtr_inliers = mtr_results[metric]<=mtr_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_mtr_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, pf=None, whis=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "\n",
    "\n",
    "barte_outliers = ~barte_nonoutliers\n",
    "mtr_outliers = ~mtr_nonoutliers\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_bad.shape[0]) if bool(both_bad[i])])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_merged\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric, histograms=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "\n",
    "\n",
    "barte_outliers = composite_results[metric]>barte_maxval\n",
    "mtr_outliers = mtr_results[metric]>barte_maxval\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_bad.shape[0]) if bool(both_bad[i])])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_barte_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric, histograms=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barte_outliers = composite_results[metric]>mtr_maxval\n",
    "mtr_outliers = mtr_results[metric]>mtr_maxval\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_bad.shape[0]) if bool(both_bad[i])])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_mtr_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, pf=None, whis=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# idx_good = plot_outliers([composite_results, mtr_results, mixnet_results, bezier_results], plots_dir, fulldset, N=25, metric_key=\"ade\", worst=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sample = fulldset[idx_good[26]]\n",
    "from scipy.spatial.transform import Rotation\n",
    "from matplotlib.collections import LineCollection, Collection\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap, Colormap\n",
    "from matplotlib.legend_handler import HandlerLineCollection\n",
    "from matplotlib.patches import ArrowStyle\n",
    "import matplotlib.cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import matplotlib.axes, matplotlib.figure\n",
    "class HandlerColorLineCollection(HandlerLineCollection):\n",
    "    def create_artists(self, legend, artist ,xdescent, ydescent,\n",
    "                        width, height, fontsize,trans):\n",
    "        x = np.linspace(0,width,self.get_numpoints(legend)+1)\n",
    "        y = np.zeros(self.get_numpoints(legend)+1)+height/2.-ydescent\n",
    "        points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "        lc = LineCollection(segments, cmap=artist.cmap,\n",
    "                     transform=trans, linestyle=artist.get_linestyle())\n",
    "        lc.set_array(x)\n",
    "        lc.set_linewidth(artist.get_linewidth())\n",
    "        return [lc]\n",
    "def add_colored_line(points : np.ndarray, cvals : np.ndarray, ax : matplotlib.axes.Axes, cmap : str | Colormap, \n",
    "    linestyle=\"solid\", alpha=1.0) -> tuple[LineCollection, Collection]:\n",
    "    points_exp = points.reshape(-1, 1, points.shape[-1])\n",
    "    segments = np.concatenate([points_exp[:-1], points_exp[1:]], axis=1)\n",
    "    norm = plt.Normalize(cvals.min(), cvals.max())\n",
    "    lc = LineCollection(segments, cmap=cmap, norm=norm,linestyle=linestyle, alpha=alpha)\n",
    "    \n",
    "    lc.set_array(cvals)\n",
    "    line = ax.add_collection(lc)\n",
    "    return lc, line\n",
    "# mtr_outliers = ~mtr_nonoutliers\n",
    "# mtr_outliers_idx = np.where(mtr_outliers)[0]\n",
    "mtr_argsort = np.flipud(np.argsort(mtr_results[\"ade\"]))\n",
    "# idx_rand = np.random.choice(mtr_outliers_idx)\n",
    "idx_rand = mtr_argsort[7]\n",
    "sample = fulldset[idx_rand]\n",
    "print(idx_rand)\n",
    "print(sample.keys())\n",
    "\n",
    "Rmat = Rotation.from_rotvec([0.0, 0.0, 0.5*np.pi]).as_matrix()[0:2,0:2]\n",
    "history_start = 30\n",
    "history = (Rmat @ sample[\"hist\"][history_start:,[0,1]].T).T\n",
    "history_vels = (Rmat @ sample[\"hist_vel\"][history_start:,[0,1]].T).T\n",
    "history_speeds = np.linalg.norm(history_vels, ord=2.0, axis=1)\n",
    "\n",
    "ground_truth = (Rmat @ sample[\"fut\"][:,[0,1]].T).T\n",
    "ground_truth_vels = (Rmat @ sample[\"fut_vel\"][:,[0,1]].T).T\n",
    "ground_truth_speeds = np.linalg.norm(ground_truth_vels, ord=2.0, axis=1)\n",
    "\n",
    "all_points = np.concatenate([history, ground_truth], axis=0)\n",
    "all_speeds = np.concatenate([history_speeds, ground_truth_speeds], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "thistory = sample[\"thistory\"]\n",
    "tfuture = sample[\"tfuture\"]\n",
    "future_left_bd = (Rmat @ sample[\"future_left_bd\"][:,[0,1]].T).T\n",
    "future_right_bd = (Rmat @ sample[\"future_right_bd\"][:,[0,1]].T).T\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "asdf : tuple[matplotlib.figure.Figure, matplotlib.axes.Axes] = plt.subplots(1,1)\n",
    "fig : matplotlib.figure.Figure = asdf[0]\n",
    "ax : matplotlib.axes.Axes = asdf[1]\n",
    "ax.plot(future_left_bd[:,0], future_left_bd[:,1], linestyle=\"solid\", color=\"black\")\n",
    "boundaries = ax.plot(future_right_bd[:,0], future_right_bd[:,1], linestyle=\"solid\", color=\"black\")\n",
    "norm = plt.Normalize(all_speeds.min(), all_speeds.max(), clip=True)\n",
    "cmap = \"RdYlGn\"\n",
    "scalar_mappable = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "lc_hist, line_hist = add_colored_line(history, history_speeds[:-1], ax, cmap, linestyle=\"dotted\")\n",
    "lc_ground_truth, line_ground_truth  = add_colored_line(ground_truth, ground_truth_speeds[:-1], ax, cmap)\n",
    "line_ground_truth.set_label(\"asdf\")\n",
    "lc_ground_truth.set_label(\"asdf\")\n",
    "# lc_fake, line_fake  = add_colored_line(all_points, all_speeds[:-1], ax, cmap, alpha=0.25)\n",
    "\n",
    "# ax.plot(history[:,0], history[:,1], linestyle=\"--\", color=history_speeds, cmap=\"viridis\", norm=norm, alpha=0.5, label=\"History\")\n",
    "# ax.plot(ground_truth[:,0], ground_truth[:,1], linestyle=\"dotted\", color=\"black\", label=\"Ground Truth\")\n",
    "ax.axis(\"equal\")\n",
    "ax.legend([\n",
    "               lc_hist, \n",
    "               lc_ground_truth,\n",
    "               boundaries[0],\n",
    "           ],\n",
    "           [\n",
    "               \"History\", \n",
    "               \"Ground Truth\", \n",
    "               \"Boundaries\",\n",
    "           ], loc=(0.1, 0.5),\n",
    "          handler_map={\n",
    "              lc_hist: HandlerColorLineCollection(numpoints=4),\n",
    "              lc_ground_truth: HandlerColorLineCollection(numpoints=4),\n",
    "\n",
    "            },\n",
    "            framealpha=1)\n",
    "fig.tight_layout()\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.savefig(os.path.join(plots_dir, \"label_nobar.svg\"), pad_inches=0.02)\n",
    "fig.savefig(os.path.join(plots_dir, \"label_nobar.pdf\"), pad_inches=0.02)\n",
    "fig.colorbar(scalar_mappable, ax=ax)\n",
    "fig.savefig(os.path.join(plots_dir, \"label.svg\"), pad_inches=0.02)\n",
    "fig.savefig(os.path.join(plots_dir, \"label.pdf\"), pad_inches=0.02)\n",
    "# fig2  = plt.figure()\n",
    "# plt.plot(thistory, history_speeds)\n",
    "# plt.plot(tfuture, ground_truth_speeds)\n",
    "plt.show()\n",
    "print(history_speeds)\n",
    "# plt.close(fig=fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.artist\n",
    "import matplotlib.collections\n",
    "import matplotlib.lines\n",
    "import matplotlib.axes\n",
    "plt.rcParams[\"text.usetex\"]=True\n",
    "results_list = all_results_mtr_ref\n",
    "ref_results = results_list[0]\n",
    "ref_alpha=1.0\n",
    "nonref_alpha=0.25\n",
    "\n",
    "artist_dict : dict[str,matplotlib.lines.Line2D | matplotlib.collections.PathCollection] = dict()\n",
    "fig, _axmain_ = plt.subplots()\n",
    "axmain : matplotlib.axes.Axes = _axmain_\n",
    "history_label = \"History\"\n",
    "artist_dict[history_label] = axmain.plot(history[:,0], history[:,1], label=history_label, linestyle=\"--\", c=\"grey\")[0]\n",
    "ground_truth_label = \"Ground Truth\"\n",
    "artist_dict[ground_truth_label] = axmain.scatter(ground_truth[:,0], ground_truth[:,1], label=ground_truth_label, c=\"grey\", alpha=0.5, s=10.0)\n",
    "print(ref_results[\"predictions\"][idx_rand].shape)\n",
    "mtr_predictions = (Rmat @ ref_results[\"predictions\"][idx_rand][:,[0,1]].T).T\n",
    "p0 = ground_truth[-1] - 6.0\n",
    "pf = mtr_predictions[-1] + 4.5\n",
    "delta = pf - p0\n",
    "artist_dict[ref_results.modelname] = axmain.plot(mtr_predictions[:,0], mtr_predictions[:,1], label=ref_results.modelname, alpha=ref_alpha)[0]\n",
    "predictions_dict : dict[str,np.ndarray] = dict()\n",
    "predictions_dict[mtr_results.modelname] = mtr_predictions\n",
    "predictions_dict[\"Ground Truth\"] = ground_truth\n",
    "predictions_inset_dict : dict[str,np.ndarray] = dict()\n",
    "p0deltas = mtr_predictions - p0[None]\n",
    "pfdeltas = -mtr_predictions + pf[None]\n",
    "predictions_inset_dict[mtr_results.modelname] = mtr_predictions[np.prod(p0deltas>0.0, axis=1, dtype=bool)*np.prod(pfdeltas>0.0, axis=1, dtype=bool)].copy()\n",
    "p0deltas = ground_truth - p0[None]\n",
    "pfdeltas = -ground_truth + pf[None]\n",
    "ground_truth_inset = ground_truth[np.prod(p0deltas>0.0, axis=1, dtype=bool)*np.prod(pfdeltas>0.0, axis=1, dtype=bool)].copy()\n",
    "for (idx, results) in enumerate(results_list):\n",
    "    if results==ref_results:\n",
    "        continue\n",
    "    predictions = (Rmat @ results[\"predictions\"][idx_rand][:,[0,1]].T).T\n",
    "    if results.modelname==composite_results.modelname:\n",
    "        label=\"BART\\\\`e\"\n",
    "    else:\n",
    "        label=results.modelname\n",
    "    artist_dict[results.modelname] = axmain.plot(predictions[:,0], predictions[:,1], label=label, alpha=nonref_alpha)[0]\n",
    "    predictions_dict[results.modelname] = predictions.copy()\n",
    "    p0deltas = predictions - p0[None]\n",
    "    pfdeltas = -predictions + pf[None]\n",
    "    predictions_inset_dict[results.modelname] = predictions[np.prod(p0deltas>0.0, axis=1, dtype=bool)*np.prod(pfdeltas>0.0, axis=1, dtype=bool)].copy()\n",
    "barte_predictions = predictions_dict[composite_results.modelname]\n",
    "mixnet_predictions = predictions_dict[mixnet_results.modelname]\n",
    "\n",
    "left_bound_input = sample[\"left_bd\"]\n",
    "artist_dict[\"left_bound\"] = axmain.plot(future_left_bd[:,0], future_left_bd[:,1], color=\"black\")[0]\n",
    "right_bound_input = sample[\"right_bd\"]\n",
    "artist_dict[\"right_bound\"] = axmain.plot(future_right_bd[:,0], future_right_bd[:,1], color=artist_dict[\"left_bound\"].get_color())[0]\n",
    "axmain.axis(\"equal\")\n",
    "fig.canvas.draw()\n",
    "margins = axmain.margins()\n",
    "xlim = np.asarray(axmain.get_xlim())\n",
    "ylim = np.asarray(axmain.get_ylim())\n",
    "lim_deltas = np.asarray([xlim[1] - xlim[0], ylim[1] - ylim[0]])\n",
    "inset_origin = np.asarray([50, -10])\n",
    "inset_origin_norm = (inset_origin - np.asarray([xlim[0], ylim[0]]))/lim_deltas\n",
    "axinset : matplotlib.axes.Axes = axmain.inset_axes(\n",
    "    [\n",
    "        inset_origin_norm[0], \n",
    "        inset_origin_norm[1], \n",
    "        0.23, \n",
    "        0.23],\n",
    "    xlim=(p0[0], pf[0]), ylim=(p0[1], pf[1]), xticklabels=[], yticklabels=[])\n",
    "for (k, v) in predictions_inset_dict.items():\n",
    "    mplobject = artist_dict[k]\n",
    "    if type(mplobject) is matplotlib.collections.PathCollection:\n",
    "        color = mplobject.get_facecolor()\n",
    "    elif type(mplobject) is matplotlib.lines.Line2D:\n",
    "        color = mplobject.get_color()\n",
    "    else:\n",
    "        raise ValueError(\"?\")\n",
    "    axinset.plot(v[:,0], v[:,1], label=k, color=color, alpha=0.5)\n",
    "axinset.scatter(ground_truth_inset[:,0], ground_truth_inset[:,1], label=\"Ground Truth\", c=\"grey\", alpha=1.0, s=10.0)\n",
    "theta = (np.pi/180.0)*37.5\n",
    "fontsize=10\n",
    "label_lines=[\"End of\",\n",
    "            \"ground-truth\",\n",
    "            \"trajectory\"]\n",
    "label=\"\"\n",
    "for line in label_lines:\n",
    "    label+=line\n",
    "    label+=\"\\n\"\n",
    "label = label.strip()\n",
    "gtend_annotation = axinset.annotate(label, \n",
    "                        ground_truth_inset[-1], xycoords=\"data\",\n",
    "                       xytext=90.0*np.asarray([-0.2, 1.0]), textcoords=\"axes points\", fontsize=fontsize,\n",
    "                       arrowprops=dict(arrowstyle=ArrowStyle.CurveB()),\n",
    "                       annotation_clip=False, multialignment=\"center\")\n",
    "label_lines=[\"MTR has large\",\n",
    "            \"longituindal error,\",\n",
    "            \"predicting the vehicle\",\n",
    "            \"will travel significantly\",\n",
    "            \"farther than the\",\n",
    "            \"ground-truth\"]\n",
    "label=\"\"\n",
    "for line in label_lines:\n",
    "    label+=line\n",
    "    label+=\"\\n\"\n",
    "label = label.strip()\n",
    "gtend_annotation = axinset.annotate(label, \n",
    "                        mtr_predictions[-1], xycoords=\"data\",\n",
    "                       xytext=105.0*np.asarray([0.5, -1.0]), textcoords=\"axes points\", fontsize=fontsize,\n",
    "                       arrowprops=dict(arrowstyle=ArrowStyle.CurveB()),\n",
    "                       annotation_clip=False, multialignment=\"center\")\n",
    "axmain.indicate_inset_zoom(axinset, edgecolor=\"black\")\n",
    "axmain.get_xaxis().set_ticks([])\n",
    "axmain.get_yaxis().set_ticks([])\n",
    "for pos in ['right', 'top', 'bottom', 'left']: \n",
    "    axmain.spines[pos].set_visible(False) \n",
    "axmain.legend()#loc=\"upper left\", bbox_to_anchor=(0.25, 1.0))\n",
    "# xticks = np.linspace(p0[0]+0.1*delta[0], pf[0]-0.1*delta[0], num=3)\n",
    "# yticks = np.linspace(p0[1]+0.1*delta[1], pf[1]-0.1*delta[1], num=3)\n",
    "historymin = np.min(history[:,0])\n",
    "historymax = np.max(history[:,0])\n",
    "axmain.set_xlim(historymin, historymax + 2.0)\n",
    "xticks = np.asarray([ground_truth[-1,0], mtr_predictions[-1,0]])\n",
    "yticks = np.asarray([ground_truth[-1,1], mtr_predictions[-1,1]])\n",
    "# xticks = yticks = []\n",
    "axinset.set_xticks(xticks, [\"%3.2f\" % float(v) for v in xticks])\n",
    "axinset.set_yticks(yticks, [\"%3.2f\" % float(v) for v in yticks])\n",
    "axinset.yaxis.tick_right()\n",
    "axinset.yaxis.set_label_position(\"right\")\n",
    "axinset.set_xlabel(\"X position (m)\")\n",
    "axinset.set_ylabel(\"Y position (m)\")\n",
    "# axinset.legend()\n",
    "# fig.canvas.draw()\n",
    "fig.tight_layout(pad=0.1)\n",
    "fig.savefig(os.path.join(plots_dir, \"example_predictions.pgf\"), pad_inches=0.02)\n",
    "fig.savefig(os.path.join(plots_dir, \"example_predictions.pdf\"), pad_inches=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepracing_models.math_utils\n",
    "from matplotlib.markers import MarkerStyle\n",
    "\n",
    "print(composite_results.keys())\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float64\n",
    "predicted_curve = torch.as_tensor(composite_results[\"curves\"][idx_rand], device=device, dtype=dtype)\n",
    "predicted_curve = (torch.as_tensor(Rmat, device=device, dtype=dtype)[None, None] @ predicted_curve[...,None]).squeeze(-1)\n",
    "tfuture_torch = torch.as_tensor(tfuture - tfuture[0], device=device, dtype=dtype)\n",
    "tswitch = torch.linspace(0.0, tfuture_torch[-1], steps=predicted_curve.shape[0] + 1, device=device, dtype=dtype)\n",
    "tstart = tswitch[:-1]\n",
    "dt = tswitch[1:] - tstart\n",
    "bezier_order = predicted_curve.shape[-2] - 1\n",
    "predicted_vel_curve = bezier_order*(predicted_curve[:,1:] - predicted_curve[:,:-1])/dt[...,None,None]\n",
    "\n",
    "\n",
    "tsamp_torch = torch.linspace(0.0, tfuture_torch[-1].item(), steps=25, dtype=dtype, device=device)\n",
    "\n",
    "tsamp_torch_dense = torch.linspace(0.0, tfuture_torch[-1].item(), steps=600, dtype=dtype, device=device)\n",
    "predicted_positions_dense, idx_buckets_dense = deepracing_models.math_utils.compositeBezierEval(tstart, dt, predicted_curve, tsamp_torch_dense)\n",
    "\n",
    "predicted_vels, _ = deepracing_models.math_utils.compositeBezierEval(tstart, dt, predicted_vel_curve, tsamp_torch)\n",
    "\n",
    "fig_positions, _ax_positions_ = plt.subplots()\n",
    "ax_positions : matplotlib.axes.Axes = _ax_positions_\n",
    "segments_colors = []\n",
    "bool_idx = idx_buckets_dense==0\n",
    "current_control_points = predicted_curve[0].cpu()\n",
    "current_positions = predicted_positions_dense[bool_idx]\n",
    "current_color = ax_positions.plot(current_positions[:,0], current_positions[:,1])[0].get_color()\n",
    "ax_positions.scatter(current_control_points[:-1,0], current_control_points[:-1,1], c=current_color, label=\"Segment 0\")\n",
    "segments_colors.append(current_color)\n",
    "for curve_idx in range(1, predicted_curve.shape[0]):\n",
    "    bool_idx = idx_buckets_dense==curve_idx\n",
    "    current_positions = predicted_positions_dense[bool_idx]\n",
    "    current_color = ax_positions.plot(current_positions[:,0], current_positions[:,1])[0].get_color()\n",
    "    segments_colors.append(current_color)\n",
    "    label=\"Segment %d\" % (curve_idx,)\n",
    "\n",
    "    current_control_points = predicted_curve[curve_idx].cpu()\n",
    "    ax_positions.scatter(current_control_points[1:-1,0], current_control_points[1:-1,1], c=current_color, label=label)\n",
    "    ax_positions.scatter(current_control_points[0,0], current_control_points[0,1], c=current_color, edgecolor=None, marker=MarkerStyle(\"o\", fillstyle=\"right\"))\n",
    "    ax_positions.scatter(current_control_points[0,0], current_control_points[0,1], c=segments_colors[-2], edgecolor=None, marker=MarkerStyle(\"o\", fillstyle=\"left\"))\n",
    "ax_positions.scatter(predicted_curve[-1,-1,0], predicted_curve[-1,-1,1], c=segments_colors[-1])\n",
    "ax_positions.legend()\n",
    "# ax_positions.axis(\"equal\")\n",
    "# ax_positions.axis(\"equal\")\n",
    "predicted_positions, idx_buckets = deepracing_models.math_utils.compositeBezierEval(tstart, dt, predicted_curve, tsamp_torch)\n",
    "fig_arrows, _ax_arrows_ = plt.subplots()\n",
    "ax_arrows : matplotlib.axes.Axes = _ax_arrows_\n",
    "skip=4\n",
    "for curve_idx in range(predicted_curve.shape[0]):\n",
    "    bool_idx = idx_buckets==curve_idx\n",
    "    current_positions = predicted_positions[bool_idx]\n",
    "    current_vels = predicted_vels[bool_idx]\n",
    "    current_color = segments_colors[curve_idx]\n",
    "    label=\"Segment %d\" % (curve_idx,)\n",
    "    ax_arrows.quiver(current_positions[:,0], current_positions[:,1], current_vels[:,0], current_vels[:,-1], angles=\"xy\", color=current_color, label=label)\n",
    "ax_arrows.legend()\n",
    "# ax_arrows.axis(\"equal\")\n",
    "fig_positions.tight_layout(pad=0.1)\n",
    "fig_positions.savefig(os.path.join(plots_dir, \"positions.svg\"), pad_inches=0.02)\n",
    "fig_positions.savefig(os.path.join(plots_dir, \"positions.png\"), backend=\"agg\", pad_inches=0.02)\n",
    "fig_arrows.tight_layout(pad=0.1)\n",
    "fig_arrows.savefig(os.path.join(plots_dir, \"arrows.svg\"), pad_inches=0.02)\n",
    "fig_arrows.savefig(os.path.join(plots_dir, \"arrows.png\"), backend=\"agg\", pad_inches=0.02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310_13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
